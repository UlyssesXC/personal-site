## Toward Embodied AI

I believe:
**Next leap in Embodied AI = Grounded Vision-Language Models & Multimodal Perception + Rigorous Systems Engineering + HW/SW Co-designed Acceleration.**

I am looking for **Intern**, **Research Assistant**, or **PhD** opportunities to push that convergence forward.  
Below is what I have done—and am doing—to prepare.

---

## Quick Facts
Communication-robotics & Linux/embedded-systems engineer **pivoting to AI-driven embodied intelligence**

- **Research interests:**  
  - Robot manipulation & grasping  
  - Multimodal / vision-language models for action grounding & large-model planning  
  - Efficient on-device inference & safe human-robot collaboration  
- **Technical stack:**  
  C/C++, Python, Linux & Docker,    
  Embedded system design,   
  ARM NEON/SIMD (vector acceleration on ARM), CUDA (learning)  
  Robotic: building platforms from scratch(ROS, SDKs, etc), simulation, motion planning & trajectory optimization, kinematics/dynamics modeling, optics engineering  
  Comm: signal processing & filtering, IoT protocols, 5G/4G/3GPP, embedded/industrial buses (EtherCAT, CAN)  

Technical stack:
C/C++, Python, Linux & Docker,
Embedded system design,   
ARM NEON/SIMD (vector acceleration on ARM), CUDA (learning)  
Robotic: building platforms from scratch(ROS, SDKs, etc), simulation, motion planning & trajectory optimization, kinematics/dynamics modeling, optics engineering  
Comm: signal processing & filtering, IoT protocols, 5G/4G/3GPP, embedded/industrial buses (EtherCAT, CAN)  

---

## What I Build

### 1. Autonomous Inspection Robots (2023 – 2024)
![Inspection Robot Demo](public/images/projects/robot_sim.gif)

At a small startup I servered end-to-end ownership as **principal technologist**, **leading the design, verification, software & hardware development, and testing** of two production-grade robotic cells for high-speed visual inspection on production lines.

* Cut manual inspection time by **60 – 80 %** across **5 factories** (customers include major TTI downstream manufacturers).  
* **Hands-on scope:** system architecture, power/safety circuits, PLC sequencing, robotic-arm motion planning, computer-vision pipelines (YOLO, traditional CV, unsupervised methods) with edge deployment of lightweight models.  
* **Toolchain mastery:** operated **10 + industrial robot brands** via teach pendants, ROS-Industrial, vendor SDKs, Ethernet/IP, PROFINET & OPC UA.  
* **Imaging expertise:** line-scan, structured-light 3-D, time-of-flight, hyperspectral — skilled at tailoring optical setups to engineering needs and optimising imaging pipelines.

### 2. 5 G PHY Optimisation @ Nokia (2020 – 2022)
![5G PHY Optimisation](./media/nokia_5g.gif)

Embedded-software engineer accelerating base-station Layer-1 on ARM platforms.

* Implemented & optimised **LDPC / polar decoding, channel estimation, beam-forming** and other physical-layer kernels in C/assembly with ARM NEON & DSP intrinsics, realising **≈ 20 % throughput uplift** under the same power budget.  
* **From ARM NEON to CUDA — bridging low-level signal-processing optimisation to large-model acceleration:** this journey exposed deep commonalities with GPU & heterogeneous compute; I am now **studying CUDA for large-model deployment & acceleration**, documenting the process in a technical blog series.

---

## Education & Awards
- **M.Eng. in Electrical & Computer Engineering,** Western University — focus on signal processing, filtering, and elective coursework in robotics  
- **B.Eng. in Electronic Information,** Hangzhou City University (formerly Zhejiang University City College)  
  - **1st Prize (2018)** & **3rd Prize (2019)** — TI Cup National Undergraduate Electronic Design Contest  

---

[**Download my full CV →**](./resume/Chen_Xiangchao_CV.pdf)
