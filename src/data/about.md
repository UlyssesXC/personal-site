## Toward Embodied AI

I believe:
**Next leap in Embodied AI = Grounded Vision-Language Models & Multimodal Perception + Rigorous Systems Engineering + HW/SW Co-designed Acceleration.**

I am looking for **Intern**, **Research Assistant**, or **PhD** opportunities to push that convergence forward.  
Below is what I have done—and am doing—to prepare.

---

## Quick Facts
Communication-robotics & Linux/embedded-systems engineer **pivoting to AI-driven embodied intelligence**

- **Research interests:**  
  - Robot manipulation & grasping  
  - Multimodal / vision-language models for action grounding & large-model planning  
  - Efficient on-device inference & safe human-robot collaboration  
- **Technical stack:**  
  C/C++, Python, Linux & Docker,    
  Embedded system design,   
  ARM NEON/SIMD (vector acceleration on ARM), CUDA (learning)  
  Robotic: building platforms from scratch(ROS, SDKs, etc), simulation, motion planning & trajectory optimization, kinematics/dynamics modeling, optics engineering  
  Comm: signal processing & filtering, IoT protocols, 5G/4G/3GPP, embedded buses (EtherCAT, CAN)  

---

## What I Build

### 1. Autonomous Inspection Robots (2023 – 2024)
<img
  src="https://github.com/UlyssesXC/personal-site/blob/1a41f98793fb51e44c65b52f8963ca9758a7d1b9/public/images/projects/robot_sim.gif?raw=true"
  alt="Inspection Robot Simulate"
  width="30%">
<img
  src="https://github.com/UlyssesXC/personal-site/blob/main/public/images/projects/robot_work.gif?raw=true"
  alt="Product working 1"
  width="30%">

<img
  src="https://github.com/UlyssesXC/personal-site/blob/main/public/images/projects/pneumatic_gripper.gif?raw=true"
  alt="Product working 2"
  width="30%">

<!-- ![Inspection Robot Simulate](https://github.com/UlyssesXC/personal-site/blob/1a41f98793fb51e44c65b52f8963ca9758a7d1b9/public/images/projects/robot_sim.gif?raw=true)
![Product working 1](https://github.com/UlyssesXC/personal-site/blob/main/public/images/projects/robot_work.gif?raw=true)
![Product working 2](https://github.com/UlyssesXC/personal-site/blob/main/public/images/projects/pneumatic_gripper.gif?raw=true) -->


- At a small startup group I servered end-to-end ownership as principal technologist, **leading the design, verification, software & hardware development, and testing** of two robotic cells for high-speed inspection on production lines.
<!-- * Cut manual inspection time by **60 – 80 %** across **5 factories** (customers include major TTI downstream manufacturers).   -->
* **Hands-on scope:** HW/SW system design, robot control, QT HIM, power circuits, PLC, computer-vision pipelines (YOLO, traditional CV, unsupervised methods) with edge deployment of lightweight models.  
* **Toolchain mastery:** operated **10 + industrial robot families** via teach pendants, ROS, vendor SDKs, Ethernet/IP, PROFINET, etc.  
* **Imaging expertise:** skilled at tailoring optical setups to engineering needs and optimising imaging pipelines.

### 2. 5 G PHY Optimisation @ Nokia (2021 – 2022)

Embedded-software engineer accelerating base-station Layer-1 on ARM platforms.

* Implemented & optimised **LDPC / polar decoding, channel estimation, beam-forming** and other physical-layer kernels in C/assembly with ARM NEON & DSP intrinsics, realising **≈ 20 % throughput uplift** under the same power budget.  
* **From ARM NEON to CUDA — bridging low-level signal-processing optimisation to large-model acceleration:** this journey exposed deep commonalities with GPU & heterogeneous compute; I am now **studying CUDA for large-model deployment & acceleration**, documenting the process in a technical blog series.

---

## Education & Awards
- **M.Eng. in Electrical & Computer Engineering,** Western University — focus on signal processing, filtering, and elective coursework in robotics  
- **B.Eng. in Electronic Information,** Hangzhou City University (formerly Zhejiang University City College)  
  - **1st Prize (2018)** & **3rd Prize (2019)** — TI Cup National Undergraduate Electronic Design Contest  

---

<!-- [**Download my full CV →**](./resume/Chen_Xiangchao_CV.pdf) -->
